---
title: "LERD RCV Analyses new decoding"
author: "Anonymous for now"
date: "2023-06-03"
output: 
  html_document: 
    toc: yes
    number_sections: yes
---

# Overview

The data comes from younger readers tasked with reading a text aloud. The read alouds were recorded and each word produced by the students was coded as being accurate or inaccurately pronounced (i.e., miscues). Miscues were coded as words where a child made a deletion, omission, mispronunciation, substitution or self-correction when reading. 

The data used in this analysis cannot be shared due to privacy concerns. 

However, the code and methods used to analyze are shared below.

## Analyses based on oversampling the data

This will give us as many corrects as incorrects

```{r}

#this will resample from incorrect
#https://www.rdocumentation.org/packages/ROSE/versions/0.0-4/topics/ovun.sample

#install.packages("ROSE")
library(ROSE)


str(lrd_rcv_taada_lemma_cw_pruned_item_var_final, list.len = 10) #this is the data that is cleaned 
#it does not include lemmas or participant IDs
dim(lrd_rcv_taada_lemma_cw_pruned_item_var_final) #55,000 instances
table(lrd_rcv_taada_lemma_cw_pruned_item_var_final$correct) #51,000 correct and 3,000 incorrect still


51287*2 #sample size needed (this is the sample size for 0's)

over_sample_glmm_cw_pruned <- ovun.sample(correct~., data = lrd_rcv_taada_lemma_cw_pruned_item_var_final, method = "over", N = 102574, seed=123)$data
str(over_sample_glmm_cw_pruned, list.len = 10)
table(over_sample_glmm_cw_pruned$correct)

#now we have an even balance....

write.csv(over_sample_glmm_cw_pruned, "over_sampled_final_data_taada_for_glmm.csv")


```

### Descriptive stats

```{r}

over_sample_glmm_cw_pruned_2 <- over_sample_glmm_cw_pruned[,c(3:59)]

#mean
means_binary_oversample <- over_sample_glmm_cw_pruned_2 %>% 
  group_by(correct) %>% 
  summarise(across(everything(), list(mean)))

means_binary_oversample


#sd

sd_binary_oversample <- over_sample_glmm_cw_pruned_2 %>% 
  group_by(correct) %>% 
  summarise(across(everything(), list(sd)))

sd_binary_oversample


```



### Check for Multicollinearity

```{r}

str(over_sample_glmm_cw_pruned_2)

#correlation matrix with p values (requires Hmisc)
correl2 <- rcorr(as.matrix(over_sample_glmm_cw_pruned_2)) 
#correl2

# Extract the correlation coefficients
corr_r <- correl2$r

#round them to 3 decimals
corr_r_round <- round(corr_r, 3)
#corr_r_round

#lots of multicollinearity as you would expect
write.csv(corr_r_round, "mc_check_prior_to_glmm.csv")
```

**Multicollinearity**

This is not perfect because using correlation with dummy coded correct variable, but it will capture multi-collinearity

```{r}
#set correlation threshold to .0000000000001

#mc function is below##
#Function takes in two arguments, dat and dep (dep is dependent variable)
cormultlin <- function(dat, dep) {
  #Function creates a single-column correlation matrix, maincor, where only the correlations between the dependent variable and all other variables are calculated and stored.
  maincor <- cor(dat, dat[[dep]])
  #print(maincor)
  #A dataframe without the data points for the dependent variable is created to be used later to check correlation between independent variables.
  nodep <- dat
  nodep[[dep]] <- NULL
  # An empty vector to store the correct result is created
  answer <- vector()
  #Line6: An empty vector (=discard pile) is created to store the names of any independent variable that are 
  #1. Moderately/strongly correlated (r > .7) to one of the independent variables inside the answer vector (i.e. multicollinear) 
  #2. Has weaker correlation with the dependent variable than the aforementioned variable.
  discard <- vector()
  # Finds all independent variables that have a weak correlation (r > .1) to the dependent variable. 
  #Stores the results to a vector: high_cors.
  high_cors <- maincor[abs(maincor) > 0.000000000000000001 & maincor != 1,]
  #print(high_cors)
  #  Loops through the name of all of the independent variables that are moderately/strongly correlated to the dependent variable
  #starting with the variable with the strongest correlation and moving on to the weakest.
  for (i in names(sort(high_cors, decreasing=TRUE))) {
    #check if the name of the variable is in the discard pile, which would mean that the variable is moderately/strongly correlated 
    #to one of the variables in the answer vector while having a weaker correlation with the dependent variable. 
    #Skip the variable if it is in the discard pile.
    if (i %in% discard) {
      next
      #If the variable is not in the discard pile, this variable is going into the answer vector since it has the strongest correlation to the dependent variable 
      #out of all the remaining variables (since the loop is in descending order in terms of strength of the variable's correlation to the dependent variable) 
      #while not having a strong correlation with any of the variables already in the answer vector (i.e. does not show multicollinearity). 
      #Check its correlation with all other independent variables. Save the single-column correlation matrix in variable, newcor.
    } else {
      newcor <- cor(nodep, nodep[[i]])
      #Check the new correlation matrix and see if any other independent variables are highly correlated with the current variable in the loop. 
      #If any variables are highly correlated to the current variable, get the names of the variable and throw them in the discard pile 
      #since they are multicollinear with the current variable while having a weaker correlation to the dependent variable. 
      prison <- newcor[abs(newcor) > 0.69999 & newcor != 1,]
      discard <- c(discard, names(prison))
    }
    #Append the current variable in loop to the answer vector.
    answer <- c(answer, high_cors[i])
  }
  #If the answer vector is empty at the end of the loop, return string that says 'No results'. 
  #If the answer vector is not empty, return the answer vector.
  if (length(answer) == 0) {
    return('No results')
  } else {
    return(answer)
  }
}


results <- cormultlin(over_sample_glmm_cw_pruned_2, 'correct')
print(results)



```

**Select only non-multicollinear variables**

```{r}

#Let's get the row names from the results

results_df<- as.data.frame(results) #first turn the double from the function into a dataframe
row_names <- row.names(results_df) #grab up the row names
#typeof(row_names) #see what format they are.
length(row_names)
row_names #check them

#Take only the columns needed from dataframe a and create new dataframe with final variables using the row names. Print out final dataframe with ID and holistic score.

str(over_sample_glmm_cw_pruned)

final_variables_glmm_cw_pruned <- over_sample_glmm_cw_pruned %>% 
  dplyr::select("ID", "correct", all_of(row_names))

str(final_variables_glmm_cw_pruned)

#print out means

final_variables_glmm_cw_pruned_2 <- final_variables_glmm_cw_pruned[, c(2:20)]

#mean
means_binary_oversample <- final_variables_glmm_cw_pruned_2 %>% 
  group_by(correct) %>% 
  summarise(across(everything(), list(mean)))

means_binary_oversample

write_csv(means_binary_oversample, "means_final_glmm_variables.csv")


#sd

sd_binary_oversample <- final_variables_glmm_cw_pruned_2 %>% 
  group_by(correct) %>% 
  summarise(across(everything(), list(sd)))

sd_binary_oversample

write_csv(sd_binary_oversample, "sd_final_glmm_variables.csv")



```

### Scale variables

Makes for a better GLMM

```{r}

library(psych)

str(final_variables_glmm_cw_pruned)

scaled_final_variables_glmm_cw_pruned <- final_variables_glmm_cw_pruned %>% 
  mutate_at(c(3:20), ~(scale(.) %>% as.vector))

str(scaled_final_variables_glmm_cw_pruned)

```



### GLMM on Balanced Samples

```{r}

library(lme4) 
library(LMERConvenienceFunctions)
library(MuMIn)


#make outcome variable a factor
scaled_final_variables_glmm_cw_pruned$correct <- as.factor(scaled_final_variables_glmm_cw_pruned$correct)
str(scaled_final_variables_glmm_cw_pruned)

#random effects: participant 
random1_over <- glmer(correct ~ (1 | ID), scaled_final_variables_glmm_cw_pruned, family="binomial" ) 
summary(random1_over)
r.squaredGLMM(random1_over) # r2 = 0.4264840

#initial model, all variables 
#Warning: Model failed to converge with max|grad| = 0.0111734 (tol = 0.002, component 1)
#model probably too complex

model_1_over <- glmer(correct ~ 
                 num_phone_tok_aw +
                 reverse_prior_prob_vowel_tok_aw +
                 num_vowel_char_tok_aw +
                 avg_phone_per_char_cons_tok_aw +
                 min_prob_all_tok_aw +
                 num_rhymes_full_elp_tok_aw +
                 discrepancy_ratio_tok_aw +
                 number_phone_all_tok_aw +
                 min_prob_vowel_tok_aw +
                 avg_syl_length_tok_aw +
                 max_prob_cons_tok_aw +
                 avg_phone_per_char_vowel_tok_aw +
                 num_rhymes_2500_coca_tok_aw +
                 reverse_prior_prob_cons_tok_aw +
                 Conditional_Probability_Average_tok_aw +
                 Freq_N_PH_tok_aw +
                 OG_N_H_tok_aw +
                 coca_mag_log_freq_tok_aw +
                 (1 | ID), scaled_final_variables_glmm_cw_pruned, family="binomial" ) 

summary(model_1_over) #
r.squaredGLMM(model_1_over)

#what to remove and when. remove lowest z value that shows suppression
#1 OG_N_H_tok_aw (not sig and suppression) Model did not converge
#2 num_vowel_char_tok_aw (suppression lowest z) Model converged
#3 avg_syl_length_tok_aw (suppression lowest z) Model converged
#4 max_prob_cons_tok_aw (suppression lowest z) Model did not converge
#5 Freq_N_PH_tok_aw (suppression lowest z) Model converged
#6 num_rhymes_2500_coca_tok_aw (suppression lowest z) Model converged
#7 avg_phone_per_char_vowel_tok_aw (suppression lowest z)  Model did not converge, but no suppression
#8 number_phone_all_tok_aw (lowest z) Model converged

model_2_over <- glmer(correct ~ 
                 num_phone_tok_aw +
                 reverse_prior_prob_vowel_tok_aw +
                 #num_vowel_char_tok_aw +
                 avg_phone_per_char_cons_tok_aw +
                 min_prob_all_tok_aw +
                 num_rhymes_full_elp_tok_aw +
                 discrepancy_ratio_tok_aw +
                 #number_phone_all_tok_aw +
                 min_prob_vowel_tok_aw +
                 #avg_syl_length_tok_aw +
                 #max_prob_cons_tok_aw +
                 #avg_phone_per_char_vowel_tok_aw +
                 #num_rhymes_2500_coca_tok_aw +
                 reverse_prior_prob_cons_tok_aw +
                 Conditional_Probability_Average_tok_aw +
                 #Freq_N_PH_tok_aw +
                 #OG_N_H_tok_aw +
                 coca_mag_log_freq_tok_aw +
                 (1 | ID), scaled_final_variables_glmm_cw_pruned, family="binomial" ) 

#this is the final model
summary(model_2_over) 
r.squaredGLMM(model_2_over)

#compare models (random to full)

anova(random1_over,model_2_over) #they are different sig differences

```


**Confusion matrix **

```{r}
library(caret)

predictions <- as.numeric(predict(model_2_over, type="response")>0.5)

#add predictions to original dataframe

scaled_final_variables_glmm_cw_pruned$predicted <- as.factor(predictions)

str(scaled_final_variables_glmm_cw_pruned)

confusionMatrix(scaled_final_variables_glmm_cw_pruned$correct, scaled_final_variables_glmm_cw_pruned$predicted,
                mode = "everything", #what you want to report in stats
                positive="1") 




```












